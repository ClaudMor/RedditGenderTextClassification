{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Challange: *Reddit Gender Text-Classification*\n",
    "\n",
    "#### Successful Training strategy\n",
    "\n",
    "The train set has been grouped by author and the resulting texts, aggregated with `\" \".join`, have been turned into a BOW (see this [brief Kaggle tutorial](https://www.kaggle.com/matleonard/text-classification#Bag-of-Words). 80% of the resulting data has been used to train an [XGBoost](https://www.kaggle.com/alexisbcook/xgboost), which was later used to predict the remeining 20%.  \n",
    "Then, a [Document Embedding model](https://medium.com/wisio/a-gentle-introduction-to-doc2vec-db3e8c0cce5e) has been fitted on test and train texts. 80% of train vectors were later used to train a [Multi Layer Perceptron](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html), which then predicted the remaining 20% and the test set. Third, an MLP on the Counterized subredidts has been trained, just like th models above. \n",
    "The predictions on the 20% of the XGBoost and of the two MLPs were used to train and validate a final logistic regression.  \n",
    "Finally, a new XGBoost and and two new MLPs were trained on all train texts, and the predictions of the two used by the logistic regression to output the final submission.  \n",
    "\n",
    "#### Unsuccessful Training Strategy\n",
    "\n",
    "An exploration of [SpaCy](https://github.com/explosion/spaCy) was performed. One may find the relevant notebooks [here](https://github.com/pitmonticone/data-mining-challange/tree/master/spaCy). The model works and has a similar strategy to the one presented above, though its performance is lower (roc = 0.894). The exploration has been concluded with this [Stack Overflow Question](https://stackoverflow.com/questions/60821793/text-classification-with-spacy-going-beyond-the-basics-to-improve-performance), this [GitHub Issue](https://github.com/explosion/spaCy/issues/5224) and a comment to a [Feature Request](https://github.com/explosion/spaCy/issues/2253#issuecomment-605502320). \n",
    "\n",
    "### Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy & matplotlib for notebooks \n",
    "%pylab inline\n",
    "\n",
    "# Pandas for data analysis and manipulation \n",
    "import pandas as pd \n",
    "\n",
    "# Sparse matrix package for numeric data.\n",
    "from scipy import sparse\n",
    "\n",
    "# Module for word embedding (word2vector)\n",
    "import gensim  \n",
    "\n",
    "# Module for progress monitoring\n",
    "import tqdm   \n",
    "\n",
    "# Sklearn \n",
    "from sklearn.preprocessing import StandardScaler # to standardize features by removing the mean and scaling to unit variance (z=(x-u)/s)\n",
    "from sklearn.neural_network import MLPClassifier # Multi-layer Perceptron classifier which optimizes the log-loss function using LBFGS or sdg.\n",
    "from sklearn.model_selection import train_test_split # to split arrays or matrices into random train and test subsets\n",
    "from sklearn.model_selection import KFold # K-Folds cross-validator providing train/test indices to split data in train/test sets.\n",
    "from sklearn.decomposition import PCA, TruncatedSVD # Principal component analysis (PCA); dimensionality reduction using truncated SVD.\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.naive_bayes import MultinomialNB # Naive Bayes classifier for multinomial models\n",
    "\n",
    "# Matplotlib\n",
    "import matplotlib # Data visualization\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.patches as mpatches  \n",
    "\n",
    "# Seaborn\n",
    "import seaborn as sns # Statistical data visualization (based on matplotlib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the test dataset\n",
    "test_data = pd.read_csv(\"data/test_data.csv\", encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of authors\n",
    "a_test = []\n",
    "for author, group in test_data.groupby(\"author\"):\n",
    "    a_test.append(author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load predictions of all models\n",
    "y = np.load(\"../y_valid.csv.npy\") # common validation y of previous steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP on doc2vec\n",
    "x1 = np.load(\"../y_D2V-mlpClf.npy\")\n",
    "# XGB on countvectorized texts\n",
    "x2 = np.load(\"../y_predict_XGB.csv.npy\")\n",
    "# MLP on binary countvectorized subreddits\n",
    "x3 = np.load(\"../y_score_MLPs.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = np.load(\"y_testD2V.npy\")\n",
    "t2 = np.load(\"y_testXGBnS.csv.npy\")\n",
    "t3 = np.load(\"y_testMLPs.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.vstack((x3,x2,x1))\n",
    "t = np.vstack((t3,t2,t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = a.T # transpose\n",
    "T = t.T # transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the test data along the 2 dimensions of largest variance\n",
    "def plot_LSA(test_data, test_labels, savepath=\"PCA_demo.csv\", plot=True):\n",
    "        lsa = TruncatedSVD(n_components=2)\n",
    "        lsa.fit(test_data)\n",
    "        lsa_scores = lsa.transform(test_data)\n",
    "        color_mapper = {label:idx for idx,label in enumerate(set(test_labels))}\n",
    "        color_column = [color_mapper[label] for label in test_labels]\n",
    "        colors = ['orange','blue']\n",
    "        if plot:\n",
    "            plt.scatter(lsa_scores[:,0], lsa_scores[:,1], s=8, alpha=.8, c=test_labels, cmap=matplotlib.colors.ListedColormap(colors))\n",
    "            orange_patch = mpatches.Patch(color='orange', label='M')\n",
    "            blue_patch = mpatches.Patch(color='blue', label='F')\n",
    "            plt.legend(handles=[orange_patch, blue_patch], prop={'size': 20})\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))          \n",
    "plot_LSA(X, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression \n",
    "lrClf = LogisticRegression(class_weight = \"balanced\",solver = \"saga\",C = 0.00005)  #modello\n",
    "\n",
    "# Kfold percross-validation\n",
    "kf = KFold(n_splits = 10)\n",
    "\n",
    "for train_indices, test_indices in kf.split(X):\n",
    "    lrClf.fit(X[train_indices], y[train_indices])\n",
    "    print(lrClf.score(X[test_indices], y[test_indices]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scorel = lrClf.predict_proba(T)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scorel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = {'author': a_test,\n",
    "        'gender': y_scorel\n",
    "        }\n",
    "\n",
    "df = pd.DataFrame(test, columns = ['author', 'gender'])\n",
    "\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'Submission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
