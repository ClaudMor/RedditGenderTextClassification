{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_data = pd.read_csv(\"../input/dataset/train_data.csv\")\n",
    "target = pd.read_csv(\"../input/dataset/train_target.csv\")\n",
    "\n",
    "# create authors gender dictionary\n",
    "author_gender = {}\n",
    "for i in range(len(target)):\n",
    "    author_gender[target.author[i]] = target.gender[i]\n",
    "    \n",
    "# X is the aggregated comments list\n",
    "X = []\n",
    "# the genders\n",
    "y = []\n",
    "# lengths of X elements\n",
    "X_len = []\n",
    "for author, group in train_data.groupby(\"author\"):\n",
    "    X.append(group.body.str.cat(sep = \" \"))\n",
    "    X_len.append([len(group.body)])\n",
    "    y.append(author_gender[author])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing functions\n",
    "def remove_number(text):\n",
    "    num = re.compile(r'[-+]?[.\\d]*[\\d]+[:,.\\d]*')\n",
    "    return num.sub(r'NUMBER', text)\n",
    "\n",
    "def remove_URL(text):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'URL',text)\n",
    "\n",
    "def remove_repeat_punct(text):\n",
    "    rep = re.compile(r'([!?.]){2,}')\n",
    "    return rep.sub(r'\\1 REPEAT', text)\n",
    "\n",
    "# remove words that end with one or more identical letters\n",
    "def remove_elongated_words(text):\n",
    "    rep = re.compile(r'\\b(\\S*?)([a-z])\\2{2,}\\b')\n",
    "    return rep.sub(r'\\1\\2 ELONG', text)\n",
    "\n",
    "def remove_allcaps(text):\n",
    "    caps = re.compile(r'([^a-z0-9()<>\\'`\\-]){2,}')\n",
    "    return caps.sub(r'ALLCAPS', text)\n",
    "\n",
    "def transcription_smile(text):\n",
    "    eyes = \"[8:=;]\"\n",
    "    nose = \"['`\\-]\"\n",
    "    smiley = re.compile(r'[8:=;][\\'\\-]?[)dDp]')\n",
    "    return smiley.sub(r'SMILE', text)\n",
    "\n",
    "def transcription_sad(text):\n",
    "    eyes = \"[8:=;]\"\n",
    "    nose = \"['`\\-]\"\n",
    "    smiley = re.compile(r'[8:=;][\\'\\-]?[(\\\\/]')\n",
    "    return smiley.sub(r'SADFACE', text)\n",
    "\n",
    "def transcription_heart(text):\n",
    "    heart = re.compile(r'<3')\n",
    "    return heart.sub(r'HEART', text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from bs4 import BeautifulSoup   # toglie i tag html\n",
    "from nltk.corpus import stopwords \n",
    "from collections import defaultdict \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet as wn\n",
    "# tags Part of Speech (POS), because teh lemmatizer needs it\n",
    "tag_map = defaultdict(lambda : wn.NOUN)\n",
    "# wn does a grammatical analysis\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "# create lemmatizer\n",
    "word_Lemmatized = WordNetLemmatizer()\n",
    "\n",
    "def review_to_words(raw_body):\n",
    "    # remove html tags\n",
    "    body_text = BeautifulSoup(raw_body).get_text() \n",
    "    #letters_only = re.sub(\"[^a-zA-Z]\", \" \", body_text)\n",
    "    # lowercase all text\n",
    "    words = body_text.lower()\n",
    "    # remove urls\n",
    "    text = remove_URL(words)\n",
    "    # remove numbers\n",
    "    text = remove_number(text)\n",
    "    # remove smiles\n",
    "    text = transcription_sad(text)\n",
    "    text = transcription_smile(text)\n",
    "    text = transcription_heart(text)\n",
    "    text = remove_elongated_words(text)\n",
    "    words = remove_repeat_punct(text)\n",
    "    # tokenizes and pass to lemmatizer, which lemmatizes taking tags into account (see before)\n",
    "    words = word_tokenize(words)\n",
    "    # we don't remove stop words, because doing it on combination with removing the 40 (trial & error estimated parameter) most utilized words (see below) decreases performance\n",
    "    #stops = set(stopwords.words(\"english\"))                  \n",
    "    #meaningful_words = [w for w in words if not w in stops]\n",
    "    Final_words = []\n",
    "    for word, tag in pos_tag(words):\n",
    "            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
    "            Final_words.append(word_Final)\n",
    "    # returns lemmatized texts as strings \n",
    "    return( \" \".join(Final_words))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train_comments = [review_to_words(x) for x in X]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Countvectorizer, Optimize Input for model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.feature_extraction.text import TfidfVectorizer # Il CountVectorizer ha performato meglio\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer = \"word\",\n",
    "                             max_features = 2000) \n",
    "# converts in np array\n",
    "train_data_features = vectorizer.fit_transform(clean_train_comments).toarray()\n",
    "\n",
    "\n",
    "print(train_data_features.shape)\n",
    "# print vocabulary \n",
    "vocab = vectorizer.get_feature_names()\n",
    "print(vocab)\n",
    "import numpy as np\n",
    "\n",
    "# counts how many times a word appearco\n",
    "dist = np.sum(train_data_features, axis=0)\n",
    "\n",
    "for tag, count in zip(vocab, dist):\n",
    "    print(count, tag)\n",
    "    \n",
    "    # removes the 40 most utilized words\n",
    "for _ in range(40):\n",
    "    index = np.argmax(dist)\n",
    "    train_data_features = np.delete(train_data_features, index, axis = 1)\n",
    "    \n",
    "train_data_features.shape\n",
    "\n",
    "# np array\n",
    "s = np.concatenate((train_data_features,np.array(X_len)),axis = 1)\n",
    "\n",
    "# 5000 rows (one per author),  and 2000-40+1 (X_len) features\n",
    "s.shape\n",
    "\n",
    "# un np.array\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train data TruncatedSVD visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "\n",
    "# plot along the two dimensions with most variance\n",
    "\n",
    "def plot_LSA(test_data, test_labels, savepath=\"PCA_demo.csv\", plot=True):\n",
    "        lsa = TruncatedSVD(n_components=2)\n",
    "        lsa.fit(test_data)\n",
    "        lsa_scores = lsa.transform(test_data)\n",
    "        color_mapper = {label:idx for idx,label in enumerate(set(test_labels))}\n",
    "        color_column = [color_mapper[label] for label in test_labels]\n",
    "        colors = ['orange','blue']\n",
    "        if plot:\n",
    "            plt.scatter(lsa_scores[:,0], lsa_scores[:,1], s=8, alpha=.8, c=test_labels, cmap=matplotlib.colors.ListedColormap(colors))\n",
    "            orange_patch = mpatches.Patch(color='orange', label='M')\n",
    "            blue_patch = mpatches.Patch(color='blue', label='F')\n",
    "            plt.legend(handles=[orange_patch, blue_patch], prop={'size': 20})\n",
    "            plt.title('BOW + lenght comments only')\n",
    "            plt.savefig('foo.pdf')\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))          \n",
    "plot_LSA(train_data_features, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# splits\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(s, y,\n",
    "                                                      train_size=0.8, test_size=0.2,\n",
    "                                                      random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# XGBoost model with parameters set with a RandomGridSearch\n",
    "my_model = XGBRegressor(objective = \"reg:logistic\",n_estimators=10000, learning_rate=0.01, n_jobs=4,subsample = 0.9,\n",
    "                       min_child_weight = 1,max_depth=4,gamma=1.5,colsample_bytree=0.6 )\n",
    "# fits\n",
    "my_model.fit(X_train, y_train, \n",
    "             early_stopping_rounds=80,\n",
    "             #sample_weight = w,\n",
    "             eval_set=[(X_valid, y_valid)],\n",
    "             verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the fit function there is the early stop, that one may set iff there is a validation set. The early stop interrupts the training when themodel starts overfitting. But, the model that will predict the test will have no validation during training, so we get here a value and heuristicallly use it also when predicting test\n",
    "print(my_model.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# cross_val_score resets parameters of my_model and fits it on X_train and t_train with cross validation (we did it for consistency).\n",
    "kfold = KFold(n_splits=5)\n",
    "results = cross_val_score(my_model, X_train, y_train, cv=kfold, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print roc of eery fold\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# averages\n",
    "np.mean(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc plot\n",
    "y_score = my_model.predict(X_valid)\n",
    "# Roc Curve for validation data \n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thresholds = roc_curve(y_valid, y_score)\n",
    "roc_auc = auc(fpr, tpr) \n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.4f)'% roc_auc )\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation predictions\n",
    "y_predict = my_model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score as roc\n",
    "# verify\n",
    "roc(y_valid,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predictions\n",
    "np.save('y_predict_XGB.csv',y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc evaluated on train set to evaluate overfitting\n",
    "y_predict = my_model.predict(X_train)\n",
    "roc(y_train,y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thsi is the RandomGridSearch that we used to estimate the best parameters for the XGBoost\n",
    "\n",
    "```{python}\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "xgb = XGBRegressor(learning_rate=0.01, n_estimators=10000, objective='reg:logistic',\n",
    "                    silent=True, nthread=1)\n",
    "\n",
    "#n_esimators si assume indipendente e quindi ottimizzato a parte\n",
    "\n",
    " params = {\n",
    "        'min_child_weight': [1,8],\n",
    "        'gamma': [0.6,0.8],\n",
    "        'subsample': [0.9],\n",
    "        'colsample_bytree': [0.6],\n",
    "        'max_depth': [4],\n",
    "        'scale_pos_weight': [1,2.70, 10, 25, 50, 75, 100, 1000]\n",
    "        }\n",
    "\n",
    "folds = 5\n",
    "param_comb = 18 #in realtà di più\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n",
    "\n",
    "random_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb, scoring='roc_auc', n_jobs=4, cv=skf.split(X_train,y_train), verbose=3, random_state=0)\n",
    "\n",
    "print('\\n Best score for %d-fold search with %d parameter combinations:' % (folds, param_comb))\n",
    "print(random_search.best_score_)\n",
    "print('\\n Best hyperparameters:')\n",
    "print(random_search.best_params_)\n",
    "results = pd.DataFrame(random_search.cv_results_)\n",
    "results.to_csv('xgb-random-grid-search-results-01.csv', index=False)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
